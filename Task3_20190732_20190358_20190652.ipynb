{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:blue\">NLP Assignment#3</h1>\n",
    "\n",
    "***\n",
    "## Names:\n",
    "\n",
    "## Abdelrahman Mahmoud Alsayed Ibrahim          20190732\n",
    "## Youssef Yasser Ezzat                                           20190652\n",
    "## Omar Mohamed Abdelbary                                  20190358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Details:\n",
    "#### In this task, you are required to implement topic classification using the Naïve Bayes classifier using the following instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading Data: Download 5 different documents at least for training in 2 different domains (5 documents per each domain) and one document for test in each domain using Wikipedia API in python. Each document has to be at least one page (100 Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning', 'Attention (machine learning)', 'Quantum machine learning', 'Boosting (machine learning)', 'Automated machine learning', 'Data science', 'Data', 'Data (computer science)', 'Data analysis', 'Master in Data Science']\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "# 2 Different Domains\n",
    "DOMAINS = [\"Machine learning\", \"Data science\"]\n",
    "\n",
    "def loading_data(domains:list) -> list:\n",
    "    \"\"\"\n",
    "     Download 5 different documents at least for training in 2 different domains \n",
    "     (5 documents per each domain) and one document for test in each domain using Wikipedia API in python. \n",
    "     Each document has to be at least one page (100 Words)\n",
    "        \n",
    "    Args:\n",
    "    - domains: list of domains of wikipedia pages\n",
    "    \n",
    "    Returns:\n",
    "    - titles: list of documents titles\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    pages = []\n",
    "    for domain in domains:\n",
    "        wiki_titles = wikipedia.search(domain,results=6)\n",
    "        for title in wiki_titles:\n",
    "            page = wikipedia.WikipediaPage(title=title).summary\n",
    "            if wiki_titles.index(title) != 5:    \n",
    "                temp_doc = open(r\"C:\\Users\\ghost\\Desktop\\nlp assignment\\Train_{}.txt\".format(title),\"w\")\n",
    "                temp_doc.write(page)\n",
    "                temp_doc.close()\n",
    "                titles.append(title)\n",
    "            else:\n",
    "                temp_doc = open(r\"C:\\Users\\ghost\\Desktop\\nlp assignment\\Test_{}.txt\".format(title),\"w\")\n",
    "                temp_doc.write(page)\n",
    "                temp_doc.close()\n",
    "\n",
    "    return titles           \n",
    "titles = loading_data(domains=DOMAINS)\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Function class_prob (doc_label) that takes all training documents labels and calculate the probability of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine Learning', 'Machine Learning', 'Machine Learning', 'Machine Learning', 'Machine Learning', 'Data Science', 'Data Science', 'Data Science', 'Data Science', 'Data Science']\n",
      "{'Machine Learning': 0.5, 'Data Science': 0.5}\n"
     ]
    }
   ],
   "source": [
    "def class_prob(doc_labels:list) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates the probability of each class given a list of document labels.\n",
    "    \n",
    "    Args:\n",
    "    - doc_labels: a list of document labels\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary where the keys are the unique labels in doc_labels and the values are the corresponding probabilities.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for label in doc_labels:\n",
    "        class_counts[label] = class_counts.get(label, 0) + 1\n",
    "    total_docs = len(doc_labels)\n",
    "    class_probs = {label: count / total_docs for label, count in class_counts.items()}\n",
    "    return class_probs\n",
    "\n",
    "DOC_LABELS = []\n",
    "for title in titles:\n",
    "    if  'machine'.casefold() in title.casefold() :\n",
    "        DOC_LABELS.append(\"Machine Learning\")\n",
    "    if  'data'.casefold() in title.casefold() :\n",
    "        DOC_LABELS.append(\"Data Science\")\n",
    "    \n",
    "print(DOC_LABELS)\n",
    "CLASS_PROBS = class_prob(DOC_LABELS)\n",
    "print(CLASS_PROBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Function getTokens (doc) that take a preprocessed training document and return tokens (unique words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes text by splitting it into words.\n",
    "\n",
    "    Args:\n",
    "    - text: a string of text\n",
    "\n",
    "    Returns:\n",
    "    - A list of tokens.\n",
    "    \"\"\"\n",
    "    # Define a list of characters to split the text on\n",
    "    delimiters = [' ', '\\n', '\\t', '.', ',', ';', ':', '!', '?', '\"', \"'\", '(', ')', '[', ']', '{', '}', '<', '>', '/', '\\\\', '|', '@', '#', '$', '%', '^', '&', '*', '-', '_', '+', '=', '`', '~']\n",
    "    \n",
    "    # Split text into words\n",
    "    words = []\n",
    "    word = ''\n",
    "    for char in text:\n",
    "        if char in delimiters:\n",
    "            if word:\n",
    "                words.append(word)\n",
    "                word = ''\n",
    "        else:\n",
    "            word += char\n",
    "    if word:\n",
    "        words.append(word)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Function preprocessing (doc) that takes training documents and return it after needed preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in artifici neural network attent techniqu meant mimic cognit attent the effect enhanc part input data diminish part — motiv network devot focu import part data even though may small learn part data import anoth depend context train gradient descent attent like mechan introduc 1990 name like multipl modul sigma pi unit hyper network it flexibl come role soft weight chang runtim contrast standard weight must remain fix runtim use attent includ memori fast weight control learn intern spotlight attent also known transform linear self attent neural ture machin reason task differenti neural comput languag process transform lstm multi sensori data process sound imag video text perceiv list variant section mani scheme implement soft weight mechan\n",
      "----------------------------------------------------------------------\n",
      "autom machin learn automl process autom task appli machin learn real world problem automl potenti includ everi stage begin raw dataset build machin learn model readi deploy automl propos artifici intellig base solut grow challeng appli machin learn the high degre autom automl aim allow non expert make use machin learn model techniqu without requir becom expert machin learn autom process appli machin learn end end addit offer advantag produc simpler solut faster creation solut model often outperform hand design model common techniqu use automl includ hyperparamet optim meta learn neural architectur search\n",
      "----------------------------------------------------------------------\n",
      "in machin learn boost ensembl meta algorithm primarili reduc bia also varianc supervis learn famili machin learn algorithm convert weak learner strong one boost base question pose kearn valiant 1988 1989 can set weak learner creat singl strong learner a weak learner defin classifi slightli correl true classif label exampl better random guess in contrast strong learner classifi arbitrarili well correl true classif robert schapir affirm answer 1990 paper question kearn valiant signific ramif machin learn statist notabl lead develop boost when first introduc hypothesi boost problem simpli refer process turn weak learner strong learner inform hypothesi boost problem ask whether effici learn algorithm … output hypothesi whose perform slightli better random guess e weak learner impli exist effici algorithm output hypothesi arbitrari accuraci e strong learner algorithm achiev hypothesi boost quickli becam simpli known boost freund schapir arc adapt ive resampl combin gener techniqu le synonym boost\n",
      "----------------------------------------------------------------------\n",
      "in pursuit knowledg data u uk collect discret valu convey inform describ quantiti qualiti fact statist basic unit mean simpli sequenc symbol may interpret a datum individu valu collect data data usual organ structur tabl provid addit context mean may use data larger structur data may use variabl comput process data may repres abstract idea concret measur data commonli use scientif research econom virtual everi form human organiz activ exampl data set includ price indic consum price index unemploy rate literaci rate censu data in context data repres raw fact figur use manner order captur use inform data collect use techniqu measur observ queri analysi typic repres number charact may process field data data collect uncontrol situ environ experiment data data gener cours control scientif experi data analyz use techniqu calcul reason discus present visual form post analysi prior analysi raw data unprocess data typic clean outlier remov obviou instrument data entri error correct data seen smallest unit factual inform use basi calcul reason discus data rang abstract idea concret measur includ limit statist themat connect data present relev context view inform contextu connect piec inform describ data insight intellig the stock insight intellig accumul time result synthesi data inform describ knowledg data describ new oil digit economi data gener concept refer fact exist inform knowledg repres code form suitabl better usag process advanc comput technolog led advent big data usual refer larg quantiti data usual petabyt scale use tradit data analysi method comput work larg grow dataset difficult even imposs theoret speak infinit data would yield infinit inform would render extract insight intellig imposs in respons rel new field data scienc use machin learn artifici intellig ai method allow effici applic analyt method big data\n",
      "----------------------------------------------------------------------\n",
      "machin learn ml field devot understand build method let machin learn – method leverag data improv comput perform set task it seen broad subfield artifici intellig machin learn algorithm build model base sampl data known train data order make predict decis without explicitli program machin learn algorithm use wide varieti applic medicin email filter speech recognit agricultur comput vision difficult unfeas develop convent algorithm perform need task a subset machin learn close relat comput statist focus make predict use comput machin learn statist learn the studi mathemat optim deliv method theori applic domain field machin learn data mine relat field studi focus exploratori data analysi unsupervis learn some implement machin learn use data neural network way mimic work biolog brain in applic across busi problem machin learn also refer predict analyt\n",
      "----------------------------------------------------------------------\n",
      "quantum machin learn integr quantum algorithm within machin learn program the common use term refer machin learn algorithm analysi classic data execut quantum comput e quantum enhanc machin learn while machin learn algorithm use comput immens quantiti data quantum machin learn util qubit quantum oper special quantum system improv comput speed data storag done algorithm program thi includ hybrid method involv classic quantum process comput difficult subroutin outsourc quantum devic these routin complex natur execut faster quantum comput furthermor quantum algorithm use analyz quantum state instead classic data beyond quantum comput term quantum machin learn also associ classic machin learn method appli data gener quantum experi e machin learn quantum system learn phase transit quantum system creat new quantum experi quantum machin learn also extend branch research explor methodolog structur similar certain physic system learn system particular neural network for exampl mathemat numer techniqu quantum physic applic classic deep learn vice versa furthermor research investig abstract notion learn theori respect quantum inform sometim refer quantum learn theori\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import glob\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os \n",
    "\n",
    "def preprocessing(documents:list) -> list:\n",
    "    \"\"\"\n",
    "    Preprocesses a list of training documents by removing stop words, punctuation, lowercasing all text, \n",
    "    and applying stemming and lemmatization.\n",
    "\n",
    "    Args:\n",
    "    - documents: a list of training documents\n",
    "\n",
    "    Returns:\n",
    "    - A list of preprocessed documents.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    preprocessed_documents = []\n",
    "    for file in documents:\n",
    "        # Tokenize text into individual words\n",
    "        with open(file,\"r\") as doc:\n",
    "            tokens = tokenize(doc.read())\n",
    "            # Remove stop words and punctuation from the text\n",
    "            filtered_tokens = [token.lower() for token in tokens if (token not in stop_words) and (token not in string.punctuation)]\n",
    "            # Stem and lemmatize the filtered tokens\n",
    "            stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "            lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "            # Join the lemmatized tokens back into a string\n",
    "            preprocessed_doc = ' '.join(lemmatized_tokens)\n",
    "            preprocessed_documents.append(preprocessed_doc)\n",
    "    return preprocessed_documents\n",
    "\n",
    "\n",
    "docs_path = r\"C:\\Users\\ghost\\Desktop\\nlp assignment\"\n",
    "train_docs = glob.glob(os.path.join(docs_path,\"Train_*.txt\"))\n",
    "train_docs =preprocessing(train_docs) \n",
    "test_docs = glob.glob(os.path.join(docs_path,\"Test_*.txt\"))\n",
    "test_docs = preprocessing(test_docs)\n",
    "\n",
    "train_machine = []\n",
    "train_data = []\n",
    "\n",
    "for i in train_docs:\n",
    "    \n",
    "    if(i.find(\"machin\") == -1):\n",
    "        train_data.append(i)        \n",
    "    else:\n",
    "        train_machine.append(i)\n",
    "\n",
    "\n",
    "# print(train_machine[0].find('machin'))\n",
    "for i in train_machine:\n",
    "    print(i)\n",
    "    print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Function conditional_prob () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to return the number of unique words in a string\n",
    "def unique_words_count(my_string):\n",
    "    words = my_string.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "def count_string_in_list(lst, string):\n",
    "    count = 0\n",
    "    words = lst.split()\n",
    "    for i in words:\n",
    "        if i == string:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_words(preprocessed_doc):\n",
    "    \"\"\"Counts the number of words in a preprocessed document.\n",
    "\n",
    "    Args:\n",
    "      - preprocessed_doc: The preprocessed document.\n",
    "\n",
    "    Returns:\n",
    "      - The number of words in the preprocessed document.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the document into words.\n",
    "    words = preprocessed_doc.split()\n",
    "\n",
    "    # Count the number of words.\n",
    "    num_words = len(words)\n",
    "\n",
    "    return num_words\n",
    "\n",
    "\n",
    "def conditional_prob(class_label, word, train_docs):\n",
    "    \n",
    "    word_num = []\n",
    "    if(class_label == 'Machine Learning'):\n",
    "        train = train_machine\n",
    "        string = ' '.join(train_machine)\n",
    "    elif (class_label == 'Data Science'):\n",
    "        train = train_data\n",
    "        string = ' '.join(train_data)\n",
    "        \n",
    "    string1 = ' '.join(train_docs)\n",
    "    word_counter=0\n",
    "    for i in train:\n",
    "        word_num.append(count_words(i))\n",
    "        word_counter += count_string_in_list(i, word)\n",
    "            \n",
    "    k = count_words(string1)\n",
    "    count_words_class= count_words(string)\n",
    "    \n",
    "    conditional_probability = (word_counter + 1) / (k + count_words_class)\n",
    "    \n",
    "    return conditional_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the conditional_probability Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002134927412467976\n"
     ]
    }
   ],
   "source": [
    "class_label = \"Machine Learning\"\n",
    "word = \"part\"\n",
    "\n",
    "conditional_probability = conditional_prob(class_label, word, train_docs)\n",
    "print(conditional_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use the above methods to train your model and save to hard disk the probabilities of all classes and Dictionary with key and #### value->{(class, word): prob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Machine Learning', 'in'): 0.0034158838599487617,\n",
       " ('Data Science', 'in'): 0.0026867275658248252,\n",
       " ('Machine Learning', 'artifici'): 0.002134927412467976,\n",
       " ('Data Science', 'artifici'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'neural'): 0.0029888983774551663,\n",
       " ('Data Science', 'neural'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'network'): 0.0025619128949615714,\n",
       " ('Data Science', 'network'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'attent'): 0.0029888983774551663,\n",
       " ('Data Science', 'attent'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'techniqu'): 0.0034158838599487617,\n",
       " ('Data Science', 'techniqu'): 0.0026867275658248252,\n",
       " ('Machine Learning', 'meant'): 0.0008539709649871904,\n",
       " ('Data Science', 'meant'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'mimic'): 0.0012809564474807857,\n",
       " ('Data Science', 'mimic'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'cognit'): 0.0008539709649871904,\n",
       " ('Data Science', 'cognit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'the'): 0.0025619128949615714,\n",
       " ('Data Science', 'the'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'effect'): 0.0008539709649871904,\n",
       " ('Data Science', 'effect'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'enhanc'): 0.0012809564474807857,\n",
       " ('Data Science', 'enhanc'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'part'): 0.002134927412467976,\n",
       " ('Data Science', 'part'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'input'): 0.0008539709649871904,\n",
       " ('Data Science', 'input'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'data'): 0.02049530315969257,\n",
       " ('Data Science', 'data'): 0.03170338527673294,\n",
       " ('Machine Learning', 'diminish'): 0.0008539709649871904,\n",
       " ('Data Science', 'diminish'): 0.0005373455131649651,\n",
       " ('Machine Learning', '—'): 0.0008539709649871904,\n",
       " ('Data Science', '—'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'motiv'): 0.0008539709649871904,\n",
       " ('Data Science', 'motiv'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'devot'): 0.0012809564474807857,\n",
       " ('Data Science', 'devot'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'focu'): 0.0008539709649871904,\n",
       " ('Data Science', 'focu'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'import'): 0.0012809564474807857,\n",
       " ('Data Science', 'import'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'even'): 0.0012809564474807857,\n",
       " ('Data Science', 'even'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'though'): 0.0008539709649871904,\n",
       " ('Data Science', 'though'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'may'): 0.0029888983774551663,\n",
       " ('Data Science', 'may'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'small'): 0.0008539709649871904,\n",
       " ('Data Science', 'small'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'learn'): 0.018360375747224593,\n",
       " ('Data Science', 'learn'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'anoth'): 0.0008539709649871904,\n",
       " ('Data Science', 'anoth'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'depend'): 0.0008539709649871904,\n",
       " ('Data Science', 'depend'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'context'): 0.002134927412467976,\n",
       " ('Data Science', 'context'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'train'): 0.0012809564474807857,\n",
       " ('Data Science', 'train'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'gradient'): 0.0008539709649871904,\n",
       " ('Data Science', 'gradient'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'descent'): 0.0008539709649871904,\n",
       " ('Data Science', 'descent'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'like'): 0.0012809564474807857,\n",
       " ('Data Science', 'like'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'mechan'): 0.0012809564474807857,\n",
       " ('Data Science', 'mechan'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'introduc'): 0.0012809564474807857,\n",
       " ('Data Science', 'introduc'): 0.0005373455131649651,\n",
       " ('Machine Learning', '1990'): 0.0012809564474807857,\n",
       " ('Data Science', '1990'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'name'): 0.0008539709649871904,\n",
       " ('Data Science', 'name'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'multipl'): 0.0008539709649871904,\n",
       " ('Data Science', 'multipl'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'modul'): 0.0008539709649871904,\n",
       " ('Data Science', 'modul'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'sigma'): 0.0008539709649871904,\n",
       " ('Data Science', 'sigma'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'pi'): 0.0008539709649871904,\n",
       " ('Data Science', 'pi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'unit'): 0.0017079419299743809,\n",
       " ('Data Science', 'unit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'hyper'): 0.0008539709649871904,\n",
       " ('Data Science', 'hyper'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'it'): 0.0012809564474807857,\n",
       " ('Data Science', 'it'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'flexibl'): 0.0008539709649871904,\n",
       " ('Data Science', 'flexibl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'come'): 0.0008539709649871904,\n",
       " ('Data Science', 'come'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'role'): 0.0008539709649871904,\n",
       " ('Data Science', 'role'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'soft'): 0.0012809564474807857,\n",
       " ('Data Science', 'soft'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'weight'): 0.002134927412467976,\n",
       " ('Data Science', 'weight'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'chang'): 0.0008539709649871904,\n",
       " ('Data Science', 'chang'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'runtim'): 0.0012809564474807857,\n",
       " ('Data Science', 'runtim'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'contrast'): 0.0012809564474807857,\n",
       " ('Data Science', 'contrast'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'standard'): 0.0008539709649871904,\n",
       " ('Data Science', 'standard'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'must'): 0.0008539709649871904,\n",
       " ('Data Science', 'must'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'remain'): 0.0008539709649871904,\n",
       " ('Data Science', 'remain'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'fix'): 0.0008539709649871904,\n",
       " ('Data Science', 'fix'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'use'): 0.008539709649871904,\n",
       " ('Data Science', 'use'): 0.004298764105319721,\n",
       " ('Machine Learning', 'includ'): 0.0029888983774551663,\n",
       " ('Data Science', 'includ'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'memori'): 0.0008539709649871904,\n",
       " ('Data Science', 'memori'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'fast'): 0.0008539709649871904,\n",
       " ('Data Science', 'fast'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'control'): 0.0012809564474807857,\n",
       " ('Data Science', 'control'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'intern'): 0.0008539709649871904,\n",
       " ('Data Science', 'intern'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'spotlight'): 0.0008539709649871904,\n",
       " ('Data Science', 'spotlight'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'also'): 0.0025619128949615714,\n",
       " ('Data Science', 'also'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'known'): 0.0017079419299743809,\n",
       " ('Data Science', 'known'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'transform'): 0.0012809564474807857,\n",
       " ('Data Science', 'transform'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'linear'): 0.0008539709649871904,\n",
       " ('Data Science', 'linear'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'self'): 0.0008539709649871904,\n",
       " ('Data Science', 'self'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'ture'): 0.0008539709649871904,\n",
       " ('Data Science', 'ture'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'machin'): 0.013663535439795047,\n",
       " ('Data Science', 'machin'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'reason'): 0.0017079419299743809,\n",
       " ('Data Science', 'reason'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'task'): 0.002134927412467976,\n",
       " ('Data Science', 'task'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'differenti'): 0.0008539709649871904,\n",
       " ('Data Science', 'differenti'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'comput'): 0.0064047822374039285,\n",
       " ('Data Science', 'comput'): 0.006448146157979581,\n",
       " ('Machine Learning', 'languag'): 0.0008539709649871904,\n",
       " ('Data Science', 'languag'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'process'): 0.004269854824935952,\n",
       " ('Data Science', 'process'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'lstm'): 0.0008539709649871904,\n",
       " ('Data Science', 'lstm'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'multi'): 0.0008539709649871904,\n",
       " ('Data Science', 'multi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'sensori'): 0.0008539709649871904,\n",
       " ('Data Science', 'sensori'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'sound'): 0.0008539709649871904,\n",
       " ('Data Science', 'sound'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'imag'): 0.0008539709649871904,\n",
       " ('Data Science', 'imag'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'video'): 0.0008539709649871904,\n",
       " ('Data Science', 'video'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'text'): 0.0008539709649871904,\n",
       " ('Data Science', 'text'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'perceiv'): 0.0008539709649871904,\n",
       " ('Data Science', 'perceiv'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'list'): 0.0008539709649871904,\n",
       " ('Data Science', 'list'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'variant'): 0.0008539709649871904,\n",
       " ('Data Science', 'variant'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'section'): 0.0008539709649871904,\n",
       " ('Data Science', 'section'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'mani'): 0.0008539709649871904,\n",
       " ('Data Science', 'mani'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'scheme'): 0.0008539709649871904,\n",
       " ('Data Science', 'scheme'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'implement'): 0.0012809564474807857,\n",
       " ('Data Science', 'implement'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'autom'): 0.002134927412467976,\n",
       " ('Data Science', 'autom'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'automl'): 0.0025619128949615714,\n",
       " ('Data Science', 'automl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'appli'): 0.002134927412467976,\n",
       " ('Data Science', 'appli'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'real'): 0.0008539709649871904,\n",
       " ('Data Science', 'real'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'world'): 0.0008539709649871904,\n",
       " ('Data Science', 'world'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'problem'): 0.002134927412467976,\n",
       " ('Data Science', 'problem'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'potenti'): 0.0008539709649871904,\n",
       " ('Data Science', 'potenti'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'everi'): 0.0012809564474807857,\n",
       " ('Data Science', 'everi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'stage'): 0.0008539709649871904,\n",
       " ('Data Science', 'stage'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'begin'): 0.0008539709649871904,\n",
       " ('Data Science', 'begin'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'raw'): 0.0017079419299743809,\n",
       " ('Data Science', 'raw'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'dataset'): 0.0012809564474807857,\n",
       " ('Data Science', 'dataset'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'build'): 0.0017079419299743809,\n",
       " ('Data Science', 'build'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'model'): 0.0025619128949615714,\n",
       " ('Data Science', 'model'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'readi'): 0.0008539709649871904,\n",
       " ('Data Science', 'readi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'deploy'): 0.0008539709649871904,\n",
       " ('Data Science', 'deploy'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'propos'): 0.0008539709649871904,\n",
       " ('Data Science', 'propos'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'intellig'): 0.0029888983774551663,\n",
       " ('Data Science', 'intellig'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'base'): 0.0017079419299743809,\n",
       " ('Data Science', 'base'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'solut'): 0.0017079419299743809,\n",
       " ('Data Science', 'solut'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'grow'): 0.0012809564474807857,\n",
       " ('Data Science', 'grow'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'challeng'): 0.0008539709649871904,\n",
       " ('Data Science', 'challeng'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'high'): 0.0008539709649871904,\n",
       " ('Data Science', 'high'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'degre'): 0.0008539709649871904,\n",
       " ('Data Science', 'degre'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'aim'): 0.0008539709649871904,\n",
       " ('Data Science', 'aim'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'allow'): 0.0012809564474807857,\n",
       " ('Data Science', 'allow'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'non'): 0.0008539709649871904,\n",
       " ('Data Science', 'non'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'expert'): 0.0012809564474807857,\n",
       " ('Data Science', 'expert'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'make'): 0.0017079419299743809,\n",
       " ('Data Science', 'make'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'without'): 0.0012809564474807857,\n",
       " ('Data Science', 'without'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'requir'): 0.0008539709649871904,\n",
       " ('Data Science', 'requir'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'becom'): 0.0008539709649871904,\n",
       " ('Data Science', 'becom'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'end'): 0.0012809564474807857,\n",
       " ('Data Science', 'end'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'addit'): 0.0012809564474807857,\n",
       " ('Data Science', 'addit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'offer'): 0.0008539709649871904,\n",
       " ('Data Science', 'offer'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'advantag'): 0.0008539709649871904,\n",
       " ('Data Science', 'advantag'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'produc'): 0.0008539709649871904,\n",
       " ('Data Science', 'produc'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'simpler'): 0.0008539709649871904,\n",
       " ('Data Science', 'simpler'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'faster'): 0.0012809564474807857,\n",
       " ('Data Science', 'faster'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'creation'): 0.0008539709649871904,\n",
       " ('Data Science', 'creation'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'often'): 0.0008539709649871904,\n",
       " ('Data Science', 'often'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'outperform'): 0.0008539709649871904,\n",
       " ('Data Science', 'outperform'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'hand'): 0.0008539709649871904,\n",
       " ('Data Science', 'hand'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'design'): 0.0008539709649871904,\n",
       " ('Data Science', 'design'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'common'): 0.0012809564474807857,\n",
       " ('Data Science', 'common'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'hyperparamet'): 0.0008539709649871904,\n",
       " ('Data Science', 'hyperparamet'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'optim'): 0.0012809564474807857,\n",
       " ('Data Science', 'optim'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'meta'): 0.0012809564474807857,\n",
       " ('Data Science', 'meta'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'architectur'): 0.0008539709649871904,\n",
       " ('Data Science', 'architectur'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'search'): 0.0008539709649871904,\n",
       " ('Data Science', 'search'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'boost'): 0.003842869342442357,\n",
       " ('Data Science', 'boost'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'ensembl'): 0.0008539709649871904,\n",
       " ('Data Science', 'ensembl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'algorithm'): 0.005977796754910333,\n",
       " ('Data Science', 'algorithm'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'primarili'): 0.0008539709649871904,\n",
       " ('Data Science', 'primarili'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'reduc'): 0.0008539709649871904,\n",
       " ('Data Science', 'reduc'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'bia'): 0.0008539709649871904,\n",
       " ('Data Science', 'bia'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'varianc'): 0.0008539709649871904,\n",
       " ('Data Science', 'varianc'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'supervis'): 0.0008539709649871904,\n",
       " ('Data Science', 'supervis'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'famili'): 0.0008539709649871904,\n",
       " ('Data Science', 'famili'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'convert'): 0.0008539709649871904,\n",
       " ('Data Science', 'convert'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'weak'): 0.0025619128949615714,\n",
       " ('Data Science', 'weak'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'learner'): 0.004269854824935952,\n",
       " ('Data Science', 'learner'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'strong'): 0.0025619128949615714,\n",
       " ('Data Science', 'strong'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'one'): 0.0008539709649871904,\n",
       " ('Data Science', 'one'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'question'): 0.0012809564474807857,\n",
       " ('Data Science', 'question'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'pose'): 0.0008539709649871904,\n",
       " ('Data Science', 'pose'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'kearn'): 0.0012809564474807857,\n",
       " ('Data Science', 'kearn'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'valiant'): 0.0012809564474807857,\n",
       " ('Data Science', 'valiant'): 0.0005373455131649651,\n",
       " ('Machine Learning', '1988'): 0.0008539709649871904,\n",
       " ('Data Science', '1988'): 0.0005373455131649651,\n",
       " ('Machine Learning', '1989'): 0.0008539709649871904,\n",
       " ('Data Science', '1989'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'can'): 0.0008539709649871904,\n",
       " ('Data Science', 'can'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'set'): 0.0017079419299743809,\n",
       " ('Data Science', 'set'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'creat'): 0.0012809564474807857,\n",
       " ('Data Science', 'creat'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'singl'): 0.0008539709649871904,\n",
       " ('Data Science', 'singl'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'a'): 0.0017079419299743809,\n",
       " ('Data Science', 'a'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'defin'): 0.0008539709649871904,\n",
       " ('Data Science', 'defin'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'classifi'): 0.0012809564474807857,\n",
       " ('Data Science', 'classifi'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'slightli'): 0.0012809564474807857,\n",
       " ('Data Science', 'slightli'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'correl'): 0.0012809564474807857,\n",
       " ('Data Science', 'correl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'true'): 0.0012809564474807857,\n",
       " ('Data Science', 'true'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'classif'): 0.0012809564474807857,\n",
       " ('Data Science', 'classif'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'label'): 0.0008539709649871904,\n",
       " ('Data Science', 'label'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'exampl'): 0.0017079419299743809,\n",
       " ('Data Science', 'exampl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'better'): 0.0017079419299743809,\n",
       " ('Data Science', 'better'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'random'): 0.0012809564474807857,\n",
       " ('Data Science', 'random'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'guess'): 0.0012809564474807857,\n",
       " ('Data Science', 'guess'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'arbitrarili'): 0.0008539709649871904,\n",
       " ('Data Science', 'arbitrarili'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'well'): 0.0008539709649871904,\n",
       " ('Data Science', 'well'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'robert'): 0.0008539709649871904,\n",
       " ('Data Science', 'robert'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'schapir'): 0.0012809564474807857,\n",
       " ('Data Science', 'schapir'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'affirm'): 0.0008539709649871904,\n",
       " ('Data Science', 'affirm'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'answer'): 0.0008539709649871904,\n",
       " ('Data Science', 'answer'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'paper'): 0.0008539709649871904,\n",
       " ('Data Science', 'paper'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'signific'): 0.0008539709649871904,\n",
       " ('Data Science', 'signific'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'ramif'): 0.0008539709649871904,\n",
       " ('Data Science', 'ramif'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'statist'): 0.0025619128949615714,\n",
       " ('Data Science', 'statist'): 0.0053734551316496505,\n",
       " ('Machine Learning', 'notabl'): 0.0008539709649871904,\n",
       " ('Data Science', 'notabl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'lead'): 0.0008539709649871904,\n",
       " ('Data Science', 'lead'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'develop'): 0.0012809564474807857,\n",
       " ('Data Science', 'develop'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'when'): 0.0008539709649871904,\n",
       " ('Data Science', 'when'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'first'): 0.0008539709649871904,\n",
       " ('Data Science', 'first'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'hypothesi'): 0.0025619128949615714,\n",
       " ('Data Science', 'hypothesi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'simpli'): 0.0017079419299743809,\n",
       " ('Data Science', 'simpli'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'refer'): 0.0029888983774551663,\n",
       " ('Data Science', 'refer'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'turn'): 0.0008539709649871904,\n",
       " ('Data Science', 'turn'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'inform'): 0.004696840307429547,\n",
       " ('Data Science', 'inform'): 0.0053734551316496505,\n",
       " ('Machine Learning', 'ask'): 0.0008539709649871904,\n",
       " ('Data Science', 'ask'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'whether'): 0.0008539709649871904,\n",
       " ('Data Science', 'whether'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'effici'): 0.0017079419299743809,\n",
       " ('Data Science', 'effici'): 0.0005373455131649651,\n",
       " ('Machine Learning', '…'): 0.0008539709649871904,\n",
       " ('Data Science', '…'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'output'): 0.0012809564474807857,\n",
       " ('Data Science', 'output'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'whose'): 0.0008539709649871904,\n",
       " ('Data Science', 'whose'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'perform'): 0.0017079419299743809,\n",
       " ('Data Science', 'perform'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'e'): 0.002134927412467976,\n",
       " ('Data Science', 'e'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'impli'): 0.0008539709649871904,\n",
       " ('Data Science', 'impli'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'exist'): 0.0012809564474807857,\n",
       " ('Data Science', 'exist'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'arbitrari'): 0.0008539709649871904,\n",
       " ('Data Science', 'arbitrari'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'accuraci'): 0.0008539709649871904,\n",
       " ('Data Science', 'accuraci'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'achiev'): 0.0008539709649871904,\n",
       " ('Data Science', 'achiev'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'quickli'): 0.0008539709649871904,\n",
       " ('Data Science', 'quickli'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'becam'): 0.0008539709649871904,\n",
       " ('Data Science', 'becam'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'freund'): 0.0008539709649871904,\n",
       " ('Data Science', 'freund'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'arc'): 0.0008539709649871904,\n",
       " ('Data Science', 'arc'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'adapt'): 0.0008539709649871904,\n",
       " ('Data Science', 'adapt'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'ive'): 0.0008539709649871904,\n",
       " ('Data Science', 'ive'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'resampl'): 0.0008539709649871904,\n",
       " ('Data Science', 'resampl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'combin'): 0.0008539709649871904,\n",
       " ('Data Science', 'combin'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'gener'): 0.002134927412467976,\n",
       " ('Data Science', 'gener'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'le'): 0.0008539709649871904,\n",
       " ('Data Science', 'le'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'synonym'): 0.0008539709649871904,\n",
       " ('Data Science', 'synonym'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'scienc'): 0.0008539709649871904,\n",
       " ('Data Science', 'scienc'): 0.010746910263299301,\n",
       " ('Machine Learning', 'treat'): 0.0004269854824935952,\n",
       " ('Data Science', 'treat'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'singular'): 0.0004269854824935952,\n",
       " ('Data Science', 'singular'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'plural'): 0.0004269854824935952,\n",
       " ('Data Science', 'plural'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'mass'): 0.0004269854824935952,\n",
       " ('Data Science', 'mass'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'noun'): 0.0004269854824935952,\n",
       " ('Data Science', 'noun'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'sequenc'): 0.0008539709649871904,\n",
       " ('Data Science', 'sequenc'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'symbol'): 0.0008539709649871904,\n",
       " ('Data Science', 'symbol'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'datum'): 0.0008539709649871904,\n",
       " ('Data Science', 'datum'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'interpret'): 0.0008539709649871904,\n",
       " ('Data Science', 'interpret'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'digit'): 0.0008539709649871904,\n",
       " ('Data Science', 'digit'): 0.0037614185921547557,\n",
       " ('Machine Learning', 'repres'): 0.002134927412467976,\n",
       " ('Data Science', 'repres'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'binari'): 0.0004269854824935952,\n",
       " ('Data Science', 'binari'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'number'): 0.0008539709649871904,\n",
       " ('Data Science', 'number'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'system'): 0.0025619128949615714,\n",
       " ('Data Science', 'system'): 0.0026867275658248252,\n",
       " ('Machine Learning', '1'): 0.0004269854824935952,\n",
       " ('Data Science', '1'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'zero'): 0.0004269854824935952,\n",
       " ('Data Science', 'zero'): 0.0010746910263299302,\n",
       " ('Machine Learning', '0'): 0.0004269854824935952,\n",
       " ('Data Science', '0'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'instead'): 0.0008539709649871904,\n",
       " ('Data Science', 'instead'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'analog'): 0.0004269854824935952,\n",
       " ('Data Science', 'analog'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'represent'): 0.0004269854824935952,\n",
       " ('Data Science', 'represent'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'modern'): 0.0004269854824935952,\n",
       " ('Data Science', 'modern'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'post'): 0.0008539709649871904,\n",
       " ('Data Science', 'post'): 0.0010746910263299302,\n",
       " ('Machine Learning', '1960'): 0.0004269854824935952,\n",
       " ('Data Science', '1960'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'three'): 0.0004269854824935952,\n",
       " ('Data Science', 'three'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'state'): 0.0008539709649871904,\n",
       " ('Data Science', 'state'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'rest'): 0.0004269854824935952,\n",
       " ('Data Science', 'rest'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'transit'): 0.0008539709649871904,\n",
       " ('Data Science', 'transit'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'within'): 0.0008539709649871904,\n",
       " ('Data Science', 'within'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'case'): 0.0004269854824935952,\n",
       " ('Data Science', 'case'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'move'): 0.0004269854824935952,\n",
       " ('Data Science', 'move'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'parallel'): 0.0004269854824935952,\n",
       " ('Data Science', 'parallel'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'serial'): 0.0004269854824935952,\n",
       " ('Data Science', 'serial'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'sourc'): 0.0004269854824935952,\n",
       " ('Data Science', 'sourc'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'devic'): 0.0008539709649871904,\n",
       " ('Data Science', 'devic'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'temperatur'): 0.0004269854824935952,\n",
       " ('Data Science', 'temperatur'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'sensor'): 0.0004269854824935952,\n",
       " ('Data Science', 'sensor'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'quantiti'): 0.0017079419299743809,\n",
       " ('Data Science', 'quantiti'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'charact'): 0.0008539709649871904,\n",
       " ('Data Science', 'charact'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'oper'): 0.0008539709649871904,\n",
       " ('Data Science', 'oper'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'store'): 0.0004269854824935952,\n",
       " ('Data Science', 'store'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'record'): 0.0004269854824935952,\n",
       " ('Data Science', 'record'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'magnet'): 0.0004269854824935952,\n",
       " ('Data Science', 'magnet'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'optic'): 0.0004269854824935952,\n",
       " ('Data Science', 'optic'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'electron'): 0.0004269854824935952,\n",
       " ('Data Science', 'electron'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'medium'): 0.0004269854824935952,\n",
       " ('Data Science', 'medium'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'transmit'): 0.0004269854824935952,\n",
       " ('Data Science', 'transmit'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'form'): 0.0017079419299743809,\n",
       " ('Data Science', 'form'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'electr'): 0.0004269854824935952,\n",
       " ('Data Science', 'electr'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'signal'): 0.0004269854824935952,\n",
       " ('Data Science', 'signal'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'pas'): 0.0004269854824935952,\n",
       " ('Data Science', 'pas'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'via'): 0.0004269854824935952,\n",
       " ('Data Science', 'via'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'peripher'): 0.0004269854824935952,\n",
       " ('Data Science', 'peripher'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'physic'): 0.0012809564474807857,\n",
       " ('Data Science', 'physic'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'element'): 0.0004269854824935952,\n",
       " ('Data Science', 'element'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'consist'): 0.0004269854824935952,\n",
       " ('Data Science', 'consist'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'address'): 0.0004269854824935952,\n",
       " ('Data Science', 'address'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'byte'): 0.0004269854824935952,\n",
       " ('Data Science', 'byte'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'word'): 0.0004269854824935952,\n",
       " ('Data Science', 'word'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'storag'): 0.0008539709649871904,\n",
       " ('Data Science', 'storag'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'relat'): 0.0012809564474807857,\n",
       " ('Data Science', 'relat'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'databas'): 0.0004269854824935952,\n",
       " ('Data Science', 'databas'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'tabl'): 0.0008539709649871904,\n",
       " ('Data Science', 'tabl'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'sql'): 0.0004269854824935952,\n",
       " ('Data Science', 'sql'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'abstract'): 0.0017079419299743809,\n",
       " ('Data Science', 'abstract'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'key'): 0.0004269854824935952,\n",
       " ('Data Science', 'key'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'valu'): 0.0012809564474807857,\n",
       " ('Data Science', 'valu'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'pair'): 0.0004269854824935952,\n",
       " ('Data Science', 'pair'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'organ'): 0.0008539709649871904,\n",
       " ('Data Science', 'organ'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'differ'): 0.0004269854824935952,\n",
       " ('Data Science', 'differ'): 0.0026867275658248252,\n",
       " ('Machine Learning', 'type'): 0.0004269854824935952,\n",
       " ('Data Science', 'type'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'structur'): 0.0017079419299743809,\n",
       " ('Data Science', 'structur'): 0.0037614185921547557,\n",
       " ('Machine Learning', 'array'): 0.0004269854824935952,\n",
       " ('Data Science', 'array'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'graph'): 0.0004269854824935952,\n",
       " ('Data Science', 'graph'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'object'): 0.0004269854824935952,\n",
       " ('Data Science', 'object'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'string'): 0.0004269854824935952,\n",
       " ('Data Science', 'string'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'analysi'): 0.0029888983774551663,\n",
       " ('Data Science', 'analysi'): 0.006985491671144546,\n",
       " ('Machine Learning', 'inspect'): 0.0004269854824935952,\n",
       " ('Data Science', 'inspect'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'clean'): 0.0008539709649871904,\n",
       " ('Data Science', 'clean'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'goal'): 0.0004269854824935952,\n",
       " ('Data Science', 'goal'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'discov'): 0.0004269854824935952,\n",
       " ('Data Science', 'discov'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'conclus'): 0.0004269854824935952,\n",
       " ('Data Science', 'conclus'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'support'): 0.0004269854824935952,\n",
       " ('Data Science', 'support'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'decis'): 0.0008539709649871904,\n",
       " ('Data Science', 'decis'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'facet'): 0.0004269854824935952,\n",
       " ('Data Science', 'facet'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'approach'): 0.0004269854824935952,\n",
       " ('Data Science', 'approach'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'encompass'): 0.0004269854824935952,\n",
       " ('Data Science', 'encompass'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'diver'): 0.0004269854824935952,\n",
       " ('Data Science', 'diver'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'varieti'): 0.0008539709649871904,\n",
       " ('Data Science', 'varieti'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'busi'): 0.0008539709649871904,\n",
       " ('Data Science', 'busi'): 0.0032240730789897904,\n",
       " ('Machine Learning', 'social'): 0.0004269854824935952,\n",
       " ('Data Science', 'social'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'domain'): 0.0008539709649871904,\n",
       " ('Data Science', 'domain'): 0.0026867275658248252,\n",
       " ('Machine Learning', 'today'): 0.0004269854824935952,\n",
       " ('Data Science', 'today'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'play'): 0.0004269854824935952,\n",
       " ('Data Science', 'play'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'scientif'): 0.0012809564474807857,\n",
       " ('Data Science', 'scientif'): 0.0026867275658248252,\n",
       " ('Machine Learning', 'help'): 0.0004269854824935952,\n",
       " ('Data Science', 'help'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'mine'): 0.0008539709649871904,\n",
       " ('Data Science', 'mine'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'particular'): 0.0008539709649871904,\n",
       " ('Data Science', 'particular'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'focus'): 0.0012809564474807857,\n",
       " ('Data Science', 'focus'): 0.0032240730789897904,\n",
       " ('Machine Learning', 'knowledg'): 0.0017079419299743809,\n",
       " ('Data Science', 'knowledg'): 0.0037614185921547557,\n",
       " ('Machine Learning', 'discoveri'): 0.0004269854824935952,\n",
       " ('Data Science', 'discoveri'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'predict'): 0.0017079419299743809,\n",
       " ('Data Science', 'predict'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'rather'): 0.0004269854824935952,\n",
       " ('Data Science', 'rather'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'pure'): 0.0004269854824935952,\n",
       " ('Data Science', 'pure'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'descript'): 0.0004269854824935952,\n",
       " ('Data Science', 'descript'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'purpos'): 0.0004269854824935952,\n",
       " ('Data Science', 'purpos'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'cover'): 0.0004269854824935952,\n",
       " ('Data Science', 'cover'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'reli'): 0.0004269854824935952,\n",
       " ('Data Science', 'reli'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'heavili'): 0.0004269854824935952,\n",
       " ('Data Science', 'heavili'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'aggreg'): 0.0004269854824935952,\n",
       " ('Data Science', 'aggreg'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'mainli'): 0.0004269854824935952,\n",
       " ('Data Science', 'mainli'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'applic'): 0.0025619128949615714,\n",
       " ('Data Science', 'applic'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'divid'): 0.0004269854824935952,\n",
       " ('Data Science', 'divid'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'exploratori'): 0.0008539709649871904,\n",
       " ('Data Science', 'exploratori'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'eda'): 0.0004269854824935952,\n",
       " ('Data Science', 'eda'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'confirmatori'): 0.0004269854824935952,\n",
       " ('Data Science', 'confirmatori'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'cda'): 0.0004269854824935952,\n",
       " ('Data Science', 'cda'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'new'): 0.0017079419299743809,\n",
       " ('Data Science', 'new'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'featur'): 0.0004269854824935952,\n",
       " ('Data Science', 'featur'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'confirm'): 0.0004269854824935952,\n",
       " ('Data Science', 'confirm'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'falsifi'): 0.0004269854824935952,\n",
       " ('Data Science', 'falsifi'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'hypothes'): 0.0004269854824935952,\n",
       " ('Data Science', 'hypothes'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'analyt'): 0.0012809564474807857,\n",
       " ('Data Science', 'analyt'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'forecast'): 0.0004269854824935952,\n",
       " ('Data Science', 'forecast'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'linguist'): 0.0004269854824935952,\n",
       " ('Data Science', 'linguist'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'extract'): 0.0008539709649871904,\n",
       " ('Data Science', 'extract'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'textual'): 0.0004269854824935952,\n",
       " ('Data Science', 'textual'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'speci'): 0.0004269854824935952,\n",
       " ('Data Science', 'speci'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'unstructur'): 0.0004269854824935952,\n",
       " ('Data Science', 'unstructur'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'all'): 0.0004269854824935952,\n",
       " ('Data Science', 'all'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'integr'): 0.0008539709649871904,\n",
       " ('Data Science', 'integr'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'precursor'): 0.0004269854824935952,\n",
       " ('Data Science', 'precursor'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'close'): 0.0008539709649871904,\n",
       " ('Data Science', 'close'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'link'): 0.0004269854824935952,\n",
       " ('Data Science', 'link'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'visual'): 0.0008539709649871904,\n",
       " ('Data Science', 'visual'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'dissemin'): 0.0004269854824935952,\n",
       " ('Data Science', 'dissemin'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'interdisciplinari'): 0.0004269854824935952,\n",
       " ('Data Science', 'interdisciplinari'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'academ'): 0.0004269854824935952,\n",
       " ('Data Science', 'academ'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'field'): 0.0025619128949615714,\n",
       " ('Data Science', 'field'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'method'): 0.003842869342442357,\n",
       " ('Data Science', 'method'): 0.0026867275658248252,\n",
       " ('Machine Learning', 'extrapol'): 0.0004269854824935952,\n",
       " ('Data Science', 'extrapol'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'insight'): 0.0017079419299743809,\n",
       " ('Data Science', 'insight'): 0.0021493820526598604,\n",
       " ('Machine Learning', 'noisi'): 0.0004269854824935952,\n",
       " ('Data Science', 'noisi'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'underli'): 0.0004269854824935952,\n",
       " ('Data Science', 'underli'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'g'): 0.0004269854824935952,\n",
       " ('Data Science', 'g'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'natur'): 0.0008539709649871904,\n",
       " ('Data Science', 'natur'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'technolog'): 0.0008539709649871904,\n",
       " ('Data Science', 'technolog'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'medicin'): 0.0008539709649871904,\n",
       " ('Data Science', 'medicin'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'multifacet'): 0.0004269854824935952,\n",
       " ('Data Science', 'multifacet'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'describ'): 0.002134927412467976,\n",
       " ('Data Science', 'describ'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'research'): 0.0017079419299743809,\n",
       " ('Data Science', 'research'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'paradigm'): 0.0004269854824935952,\n",
       " ('Data Science', 'paradigm'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'disciplin'): 0.0004269854824935952,\n",
       " ('Data Science', 'disciplin'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'workflow'): 0.0004269854824935952,\n",
       " ('Data Science', 'workflow'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'profess'): 0.0004269854824935952,\n",
       " ('Data Science', 'profess'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'concept'): 0.0008539709649871904,\n",
       " ('Data Science', 'concept'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'unifi'): 0.0004269854824935952,\n",
       " ('Data Science', 'unifi'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'informat'): 0.0004269854824935952,\n",
       " ('Data Science', 'informat'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'understand'): 0.0008539709649871904,\n",
       " ('Data Science', 'understand'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'analyz'): 0.0012809564474807857,\n",
       " ('Data Science', 'analyz'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'actual'): 0.0004269854824935952,\n",
       " ('Data Science', 'actual'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'phenomenon'): 0.0004269854824935952,\n",
       " ('Data Science', 'phenomenon'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'theori'): 0.0017079419299743809,\n",
       " ('Data Science', 'theori'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'drawn'): 0.0004269854824935952,\n",
       " ('Data Science', 'drawn'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'mathemat'): 0.0012809564474807857,\n",
       " ('Data Science', 'mathemat'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'howev'): 0.0004269854824935952,\n",
       " ('Data Science', 'howev'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'award'): 0.0004269854824935952,\n",
       " ('Data Science', 'award'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'winner'): 0.0004269854824935952,\n",
       " ('Data Science', 'winner'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'jim'): 0.0004269854824935952,\n",
       " ('Data Science', 'jim'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'gray'): 0.0004269854824935952,\n",
       " ('Data Science', 'gray'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'imagin'): 0.0004269854824935952,\n",
       " ('Data Science', 'imagin'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'fourth'): 0.0004269854824935952,\n",
       " ('Data Science', 'fourth'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'empir'): 0.0004269854824935952,\n",
       " ('Data Science', 'empir'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'theoret'): 0.0008539709649871904,\n",
       " ('Data Science', 'theoret'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'driven'): 0.0004269854824935952,\n",
       " ('Data Science', 'driven'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'assert'): 0.0004269854824935952,\n",
       " ('Data Science', 'assert'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'everyth'): 0.0004269854824935952,\n",
       " ('Data Science', 'everyth'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'impact'): 0.0004269854824935952,\n",
       " ('Data Science', 'impact'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'delug'): 0.0004269854824935952,\n",
       " ('Data Science', 'delug'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'scientist'): 0.0004269854824935952,\n",
       " ('Data Science', 'scientist'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'profession'): 0.0004269854824935952,\n",
       " ('Data Science', 'profession'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'program'): 0.0017079419299743809,\n",
       " ('Data Science', 'program'): 0.0016120365394948952,\n",
       " ('Machine Learning', 'code'): 0.0008539709649871904,\n",
       " ('Data Science', 'code'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'pursuit'): 0.0008539709649871904,\n",
       " ('Data Science', 'pursuit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'u'): 0.0008539709649871904,\n",
       " ('Data Science', 'u'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'uk'): 0.0008539709649871904,\n",
       " ('Data Science', 'uk'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'collect'): 0.002134927412467976,\n",
       " ('Data Science', 'collect'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'discret'): 0.0008539709649871904,\n",
       " ('Data Science', 'discret'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'convey'): 0.0008539709649871904,\n",
       " ('Data Science', 'convey'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'qualiti'): 0.0008539709649871904,\n",
       " ('Data Science', 'qualiti'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'fact'): 0.0017079419299743809,\n",
       " ('Data Science', 'fact'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'basic'): 0.0008539709649871904,\n",
       " ('Data Science', 'basic'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'mean'): 0.0012809564474807857,\n",
       " ('Data Science', 'mean'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'individu'): 0.0008539709649871904,\n",
       " ('Data Science', 'individu'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'usual'): 0.0017079419299743809,\n",
       " ('Data Science', 'usual'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'provid'): 0.0008539709649871904,\n",
       " ('Data Science', 'provid'): 0.0010746910263299302,\n",
       " ('Machine Learning', 'larger'): 0.0008539709649871904,\n",
       " ('Data Science', 'larger'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'variabl'): 0.0008539709649871904,\n",
       " ('Data Science', 'variabl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'idea'): 0.0012809564474807857,\n",
       " ('Data Science', 'idea'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'concret'): 0.0012809564474807857,\n",
       " ('Data Science', 'concret'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'measur'): 0.0017079419299743809,\n",
       " ('Data Science', 'measur'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'commonli'): 0.0008539709649871904,\n",
       " ('Data Science', 'commonli'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'econom'): 0.0008539709649871904,\n",
       " ('Data Science', 'econom'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'virtual'): 0.0008539709649871904,\n",
       " ('Data Science', 'virtual'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'human'): 0.0008539709649871904,\n",
       " ('Data Science', 'human'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'organiz'): 0.0008539709649871904,\n",
       " ('Data Science', 'organiz'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'activ'): 0.0008539709649871904,\n",
       " ('Data Science', 'activ'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'price'): 0.0012809564474807857,\n",
       " ('Data Science', 'price'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'indic'): 0.0008539709649871904,\n",
       " ('Data Science', 'indic'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'consum'): 0.0008539709649871904,\n",
       " ('Data Science', 'consum'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'index'): 0.0008539709649871904,\n",
       " ('Data Science', 'index'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'unemploy'): 0.0008539709649871904,\n",
       " ('Data Science', 'unemploy'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'rate'): 0.0012809564474807857,\n",
       " ('Data Science', 'rate'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'literaci'): 0.0008539709649871904,\n",
       " ('Data Science', 'literaci'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'censu'): 0.0008539709649871904,\n",
       " ('Data Science', 'censu'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'figur'): 0.0008539709649871904,\n",
       " ('Data Science', 'figur'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'manner'): 0.0008539709649871904,\n",
       " ('Data Science', 'manner'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'order'): 0.0012809564474807857,\n",
       " ('Data Science', 'order'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'captur'): 0.0008539709649871904,\n",
       " ('Data Science', 'captur'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'observ'): 0.0008539709649871904,\n",
       " ('Data Science', 'observ'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'queri'): 0.0008539709649871904,\n",
       " ('Data Science', 'queri'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'typic'): 0.0012809564474807857,\n",
       " ('Data Science', 'typic'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'uncontrol'): 0.0008539709649871904,\n",
       " ('Data Science', 'uncontrol'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'situ'): 0.0008539709649871904,\n",
       " ('Data Science', 'situ'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'environ'): 0.0008539709649871904,\n",
       " ('Data Science', 'environ'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'experiment'): 0.0008539709649871904,\n",
       " ('Data Science', 'experiment'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'cours'): 0.0008539709649871904,\n",
       " ('Data Science', 'cours'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'experi'): 0.0017079419299743809,\n",
       " ('Data Science', 'experi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'calcul'): 0.0012809564474807857,\n",
       " ('Data Science', 'calcul'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'discus'): 0.0012809564474807857,\n",
       " ('Data Science', 'discus'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'present'): 0.0012809564474807857,\n",
       " ('Data Science', 'present'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'prior'): 0.0008539709649871904,\n",
       " ('Data Science', 'prior'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'unprocess'): 0.0008539709649871904,\n",
       " ('Data Science', 'unprocess'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'outlier'): 0.0008539709649871904,\n",
       " ('Data Science', 'outlier'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'remov'): 0.0008539709649871904,\n",
       " ('Data Science', 'remov'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'obviou'): 0.0008539709649871904,\n",
       " ('Data Science', 'obviou'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'instrument'): 0.0008539709649871904,\n",
       " ('Data Science', 'instrument'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'entri'): 0.0008539709649871904,\n",
       " ('Data Science', 'entri'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'error'): 0.0008539709649871904,\n",
       " ('Data Science', 'error'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'correct'): 0.0008539709649871904,\n",
       " ('Data Science', 'correct'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'seen'): 0.0012809564474807857,\n",
       " ('Data Science', 'seen'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'smallest'): 0.0008539709649871904,\n",
       " ('Data Science', 'smallest'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'factual'): 0.0008539709649871904,\n",
       " ('Data Science', 'factual'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'basi'): 0.0008539709649871904,\n",
       " ('Data Science', 'basi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'rang'): 0.0008539709649871904,\n",
       " ('Data Science', 'rang'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'limit'): 0.0008539709649871904,\n",
       " ('Data Science', 'limit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'themat'): 0.0008539709649871904,\n",
       " ('Data Science', 'themat'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'connect'): 0.0012809564474807857,\n",
       " ('Data Science', 'connect'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'relev'): 0.0008539709649871904,\n",
       " ('Data Science', 'relev'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'view'): 0.0008539709649871904,\n",
       " ('Data Science', 'view'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'contextu'): 0.0008539709649871904,\n",
       " ('Data Science', 'contextu'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'piec'): 0.0008539709649871904,\n",
       " ('Data Science', 'piec'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'stock'): 0.0008539709649871904,\n",
       " ('Data Science', 'stock'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'accumul'): 0.0008539709649871904,\n",
       " ('Data Science', 'accumul'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'time'): 0.0008539709649871904,\n",
       " ('Data Science', 'time'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'result'): 0.0008539709649871904,\n",
       " ('Data Science', 'result'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'synthesi'): 0.0008539709649871904,\n",
       " ('Data Science', 'synthesi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'oil'): 0.0008539709649871904,\n",
       " ('Data Science', 'oil'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'economi'): 0.0008539709649871904,\n",
       " ('Data Science', 'economi'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'suitabl'): 0.0008539709649871904,\n",
       " ('Data Science', 'suitabl'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'usag'): 0.0008539709649871904,\n",
       " ('Data Science', 'usag'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'advanc'): 0.0008539709649871904,\n",
       " ('Data Science', 'advanc'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'led'): 0.0008539709649871904,\n",
       " ('Data Science', 'led'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'advent'): 0.0008539709649871904,\n",
       " ('Data Science', 'advent'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'big'): 0.0012809564474807857,\n",
       " ('Data Science', 'big'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'larg'): 0.0012809564474807857,\n",
       " ('Data Science', 'larg'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'petabyt'): 0.0008539709649871904,\n",
       " ('Data Science', 'petabyt'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'scale'): 0.0008539709649871904,\n",
       " ('Data Science', 'scale'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'tradit'): 0.0008539709649871904,\n",
       " ('Data Science', 'tradit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'work'): 0.0012809564474807857,\n",
       " ('Data Science', 'work'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'difficult'): 0.0017079419299743809,\n",
       " ('Data Science', 'difficult'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'imposs'): 0.0012809564474807857,\n",
       " ('Data Science', 'imposs'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'speak'): 0.0008539709649871904,\n",
       " ('Data Science', 'speak'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'infinit'): 0.0012809564474807857,\n",
       " ('Data Science', 'infinit'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'would'): 0.0012809564474807857,\n",
       " ('Data Science', 'would'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'yield'): 0.0008539709649871904,\n",
       " ('Data Science', 'yield'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'render'): 0.0008539709649871904,\n",
       " ('Data Science', 'render'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'respons'): 0.0008539709649871904,\n",
       " ('Data Science', 'respons'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'rel'): 0.0008539709649871904,\n",
       " ('Data Science', 'rel'): 0.0005373455131649651,\n",
       " ('Machine Learning', 'ai'): 0.0008539709649871904,\n",
       " ('Data Science', 'ai'): 0.0005373455131649651,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = {}\n",
    "class_label1 = \"Machine Learning\"\n",
    "class_label2 = \"Data Science\"\n",
    "for i in train_docs: \n",
    "    words = i.split()\n",
    "    for j in words:\n",
    "        prob[(class_label1,j)] = conditional_prob(class_label1, j, train_docs)\n",
    "        prob[(class_label2,j)] = conditional_prob(class_label2, j, train_docs)\n",
    "        \n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train.pickle', 'wb') as handle:\n",
    "    pickle.dump(prob, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Function predict(test_doc) that take the test document and return it’s class by loading the training saved probabilities from the #### hard disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in comput scienc comput program data type simpli type collect group data valu usual specifi set possibl valu set allow oper valu represent valu machin type a data type specif program constrain possibl valu express variabl function call might take on liter data tell compil interpret programm intend use data most program languag support basic data type integ number vari size float point number approxim real number charact boolean \n",
      "\n",
      "The document is classified as a Data Science Topic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('train.pickle', 'rb') as handle:\n",
    "    Trained_model = pickle.load(handle)\n",
    "\n",
    "# dropping any unfound words from the calculations\n",
    "def predict(test_docs):\n",
    "    prob_data = 1\n",
    "\n",
    "    prob_machine = 1\n",
    "    \n",
    "    words = test_docs.split()\n",
    "    \n",
    "    for i in words:\n",
    "        if (\"Machine Learning\", i)  in Trained_model:\n",
    "           \n",
    "            prob_machine =  Trained_model[('Machine Learning', i)] * prob_machine\n",
    "            prob_data = Trained_model[('Data Science', i)] * prob_data\n",
    "            \n",
    "            \n",
    "\n",
    "    prob_machine * CLASS_PROBS[\"Machine Learning\"]\n",
    "    prob_data * CLASS_PROBS[\"Data Science\"]\n",
    "    if prob_machine/prob_data > 1:\n",
    "        \n",
    "        print(test_docs,\"\\n\")\n",
    "        return \"The document classified as a Machine Learning Topic\"\n",
    "        \n",
    "    else:\n",
    "        print(test_docs,\"\\n\")\n",
    "        return \"The document is classified as a Data Science Topic\"\n",
    "\n",
    "\n",
    "print(predict(test_docs[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
